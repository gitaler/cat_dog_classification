{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "\n",
        "import requests\n",
        "\n",
        "URL = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
        "response = requests.get(URL)\n",
        "dataset_file_name = 'dataset.zip'\n",
        "open(dataset_file_name, \"wb\").write(response.content)"
      ],
      "metadata": {
        "id": "rCogoSZRLn1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip dataset\n",
        "\n",
        "import zipfile\n",
        "\n",
        "dest_folder = 'dataset'\n",
        "with zipfile.ZipFile(dataset_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dest_folder)"
      ],
      "metadata": {
        "id": "YLUKoRm5MrMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get images stats: paths, resolutions and corrupted files\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "cats_folder = './dataset/PetImages/Cat/'\n",
        "dogs_folder = './dataset/PetImages/Dog/'\n",
        "\n",
        "def get_images_stats(dir):\n",
        "    resolutions = {}\n",
        "    imgs_file_names = os.listdir(dir)\n",
        "    file_names = []\n",
        "    corrupted_file_names = []\n",
        "    for img in imgs_file_names:\n",
        "        try:\n",
        "            composed_path = os.path.join(dir, img)\n",
        "            img_size = Image.open(composed_path).size\n",
        "            if img_size not in resolutions: resolutions[img_size] = 0\n",
        "            resolutions[img_size] += 1\n",
        "            file_names.append(composed_path)\n",
        "        except:\n",
        "            corrupted_file_names.append(composed_path)\n",
        "    return file_names, resolutions, corrupted_file_names\n",
        "\n",
        "cats_imgs, cats_resolutions, corrupted_cat_imgs = get_images_stats(cats_folder)\n",
        "dogs_imgs, dogs_resolutions, corrupted_dog_imgs = get_images_stats(dogs_folder)\n",
        "total_resolutions = {**cats_resolutions, **dogs_resolutions}"
      ],
      "metadata": {
        "id": "mwBjw-hBcIlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate average image resolution\n",
        "\n",
        "average_resolution = {'width': 0, 'height': 0}\n",
        "\n",
        "counter = 0\n",
        "for res in total_resolutions:\n",
        "  count = total_resolutions[res]\n",
        "  counter += count\n",
        "  average_resolution['width'] += res[0]*count\n",
        "  average_resolution['height'] += res[1]*count\n",
        "\n",
        "average_resolution['width'] //= counter\n",
        "average_resolution['height'] //= counter\n",
        "\n",
        "print('average_resolution', average_resolution)"
      ],
      "metadata": {
        "id": "fV5QPLg2ilsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove corrupted images\n",
        "\n",
        "corrupted = corrupted_cat_imgs + corrupted_dog_imgs\n",
        "for cor_img in corrupted:\n",
        "  if cor_img[-3:] == 'jpg': os.remove(cor_img)"
      ],
      "metadata": {
        "id": "q1sPA86HlC1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test sets folders\n",
        "\n",
        "train_cats_folder = './dataset/train/cats/'\n",
        "train_dogs_folder = './dataset/train/dogs/'\n",
        "test_cats_folder = './dataset/test/cats/'\n",
        "test_dogs_folder = './dataset/test/dogs/'\n",
        "\n",
        "os.makedirs(train_cats_folder, exist_ok=True)\n",
        "os.makedirs(train_dogs_folder, exist_ok=True)\n",
        "os.makedirs(test_cats_folder, exist_ok=True)\n",
        "os.makedirs(test_dogs_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "AbMonFFdMxZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test split: images are copied from the dataset folder to the destination folder (train or test)\n",
        "# train percentage is set to 85 %\n",
        "\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_test_folders_split(imgs_paths, train_split, train_dir_path, test_dir_path):\n",
        "    num_train_imgs = int(len(imgs_paths) * train_split)\n",
        "    random.seed(42) # for reproducibility purposes\n",
        "    random.shuffle(imgs_paths)\n",
        "    fails = []\n",
        "    for i, img_path in tqdm(enumerate(imgs_paths), total=len(imgs_paths), desc=f\"{imgs_paths[0].split('/')[-2]} splitting\"):\n",
        "        try:\n",
        "            if i < num_train_imgs: shutil.copy(img_path, f\"{train_dir_path}{img_path.split('/')[-1]}\")\n",
        "            else: shutil.copy(img_path, f\"{test_dir_path}{img_path.split('/')[-1]}\")\n",
        "        except: fails.append(img_path)\n",
        "    return fails\n",
        "\n",
        "train_percentage = 0.85\n",
        "cats_fails = train_test_folders_split(cats_imgs, train_percentage, train_cats_folder, test_cats_folder)\n",
        "dogs_fails = train_test_folders_split(dogs_imgs, train_percentage, train_dogs_folder, test_dogs_folder)\n",
        "print()\n",
        "print(len(cats_fails), cats_fails)\n",
        "print(len(dogs_fails), dogs_fails)"
      ],
      "metadata": {
        "id": "ypzVlFZDcbMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the images data generators\n",
        "# the train set generator also applies transformations to the images\n",
        "# given the different resolutions, images are all resized to a common resolution of 128x128\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "reshape_target_size = (128, 128)\n",
        "batch_size = 64\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    validation_split=0.15\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train/',\n",
        "    target_size = reshape_target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train/',\n",
        "    target_size = reshape_target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'dataset/test/',\n",
        "    target_size = reshape_target_size,\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        ")"
      ],
      "metadata": {
        "id": "KxSFKLFju2xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot some images just to check them\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_images, batch_labels = validation_generator.next()\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(batch_images[i])\n",
        "    plt.title(f\"Label: {batch_labels[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bMd_pPzKFzxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definition of the model:\n",
        "# 3 convolutional layers followed by a fully connected layer\n",
        "# dropout is applied so that the model can generalize better\n",
        "# adam optimizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "input_shape = batch_images[0].shape\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IyloAKp2EDLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I define an early stopping to avoid overfitting:\n",
        "# the validation loss is observed and if this does not\n",
        "# improve in the last 10 epochs the training stops and\n",
        "# returns the model instance that presented the minimum\n",
        "# validation loss during training\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "epochs = 100\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps= validation_generator.samples // batch_size,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "98uVBTbaEFi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classifier.keras')"
      ],
      "metadata": {
        "id": "UNNtea3SGhzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training curves\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f75y52STQ7wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(history.history)\n",
        "df.to_csv('history.csv', index=False)"
      ],
      "metadata": {
        "id": "w8TGAPiki33z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of the model on the test set reporting the various metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "total_predictions = []\n",
        "total_labels = []\n",
        "\n",
        "for i, batch in enumerate(test_generator):\n",
        "  images, labels = batch\n",
        "  preds = model.predict(images, verbose=0)\n",
        "  preds = np.where(preds<0.5,0,1)\n",
        "  preds = list(map(lambda x: x[0], preds))\n",
        "  total_predictions = total_predictions + preds\n",
        "  total_labels = total_labels + list(labels)\n",
        "  if i == len(test_generator)-1: break\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(total_labels, total_predictions))\n",
        "print(\"Precision:\", precision_score(total_labels, total_predictions))\n",
        "print(\"Recall:   \", recall_score(total_labels, total_predictions))\n",
        "print(\"F1-score: \", f1_score(total_labels, total_predictions))"
      ],
      "metadata": {
        "id": "eAbz8Xae3gnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(confusion_matrix(total_labels, total_predictions),\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Blues',\n",
        "            xticklabels=test_generator.class_indices,\n",
        "            yticklabels=test_generator.class_indices)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8pID0-q6q19v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# continue training by loading the previous model\n",
        "\n",
        "# from keras.models import load_model\n",
        "\n",
        "# model_two = load_model('classifier.keras')\n",
        "# history_two = model_two.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=train_generator.samples // batch_size,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps= validation_generator.samples // batch_size,\n",
        "#     callbacks=[early_stopping]\n",
        "# )"
      ],
      "metadata": {
        "id": "3eVv2EHZnG--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}